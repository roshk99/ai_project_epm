The dataset includes the record of 115 students, each with 4061 timesteps, where every timestep includes the information of 8 activities!
model_parameters:
{'categories': 2, 'layers': 10, 'learning_rate': 0.001, 'epochs': 100}
setup:
{'loss_report': 1, 'train_portion': 0.75, 'test_portion': 0.25}
Loss:  0.99508744
Loss:  0.8521988
Loss:  0.73339045
Loss:  0.6084576
Loss:  0.5165285
Loss:  0.46152008
Loss:  0.42782393
Loss:  0.40604293
Loss:  0.39125153
Loss:  0.3808249
Loss:  0.37329704
Loss:  0.36780712
Loss:  0.36382732
Loss:  0.36102208
Loss:  0.35916957
Loss:  0.35811165
Loss:  0.35771924
Loss:  0.35786963
Loss:  0.35843614
Loss:  0.35929167
Loss:  0.36031967
Loss:  0.36142296
Loss:  0.3625306
Loss:  0.36359656
Loss:  0.36459514
Loss:  0.365515
Loss:  0.36635408
Loss:  0.36711535
Loss:  0.36780488
Loss:  0.3684299
Loss:  0.3689974
Loss:  0.36951423
Loss:  0.36998674
Loss:  0.37042034
Loss:  0.37081954
Loss:  0.3711888
Loss:  0.37153137
Loss:  0.37185046
Loss:  0.37214854
Loss:  0.37242794
Loss:  0.37269044
Loss:  0.37293765
Loss:  0.3731712
Loss:  0.37339216
Loss:  0.37360156
Loss:  0.37380058
Loss:  0.37398964
Loss:  0.3741699
Loss:  0.37434176
Loss:  0.3745058
Loss:  0.37466276
Loss:  0.3748128
Loss:  0.37495652
Loss:  0.37509432
Loss:  0.37522647
Loss:  0.37535343
Loss:  0.3754751
Loss:  0.3755923
Loss:  0.3757048
Loss:  0.37581304
Loss:  0.37591717
Loss:  0.37601736
Loss:  0.37611383
Loss:  0.37620673
Loss:  0.37629625
Loss:  0.37638232
Loss:  0.37646553
Loss:  0.37654555
Loss:  0.37662268
Loss:  0.37669703
Loss:  0.37676868
Loss:  0.3768378
Loss:  0.37690434
Loss:  0.37696853
Loss:  0.37703034
Loss:  0.3770899
Loss:  0.37714735
Loss:  0.37720263
Loss:  0.37725583
Loss:  0.3773071
Loss:  0.37735647
Loss:  0.37740412
Loss:  0.3774499
Loss:  0.37749395
Loss:  0.37753636
